一、python3和python2有什么区别？
python2中print是一个语句，不论想输出什么，直接放到print关键字后面即可。
python3里，print()是一个函数，像其他函数一样，print()需要你将要输出的东西作为参数传给它。

python２有两个全局函数可以把对象强制转换成字符串:unicode()把对象转换成unicode字符串，还有str()把对象转换为非Unicode字符串。
Python3只有一种字符串类型，unicode字符串，所以str()函数即可完成所有的功能。

python2有非浮点数准备的int和long类型。int类型最大值不能超过sys.maxint，而且这个最大值是平台相关的。可以通过在数字的末尾附上一个Ｌ来定义长整型，
显然，它比int类型表示的数字范围更大。
在python3里，只有一种整数类型int,大多数情况下，和python２中的长整型类似。

Python2支持<>作为!=的同义词，　python3只支持!=, 不再支持<>

Python2中，字典对象has_key()方法测试字典是否包含指定的键。python3不再支持这个方法，需要使用in.

在python2里，许多字典类方法的返回值是列表。最常用方法有keys, items和values。python3，所有以上方法的返回值改为动态试图。
在一些上下文环境里，这种改变不会产生影响。如果这些方法的返回值被立即传递给另外一个函数，而且那个函数会遍历整个序列，
那么以上方法的返回值是列表或视图并不会产生什么不同。
如果你期望获得一个被独立寻址元素的列表，那么python3的这些改变将会使你的代码卡住，因为视图不支持索引。

从python2到python3，标准库里的一些模块已经被重命名。还有一些相互关联的模块也被组合或则重新组织，使得这种关联更有逻辑性。


二、什么是GIL
它是在实现Python解析器(CPython)时所引入的一个概念，GIL并不是Python的特性，Python完全可以不依赖于GIL。
了利用多核，Python开始支持多线程。而解决多线程之间数据完整性和状态同步的最简单方法自然就是加锁
为了让各个线程能够平均利用CPU时间，python会计算当前已执行的微代码数量，达到一定阈值后就强制释放GIL。而这时也会触发一次操作系统的线程调度
任何一个线程被唤起时都能成功获得到GIL（因为只有释放了GIL才会引发线程调度）。但当CPU有多个核心的时候，问题就来了。从伪代码可以看到，
从release GIL到acquire GIL之间几乎是没有间隙的。所以当其他在其他核心上的线程被唤醒时，大部分情况下主线程已经又再一次获取到GIL了。
这个时候被唤醒执行的线程只能白白的浪费CPU时间，看着另一个线程拿着GIL欢快的执行着。然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环
GIL的存在导致多线程无法很好的立即多核CPU的并发处理能力。
用multiprocess替代Thread

multiprocess库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。
唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。

当然multiprocess也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。就拿计数器来举例子，如果我们要多个线程累加同一个变量，
对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocess由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，
put再get或者用share memory的方法。这个额外的实现成本使得本来就非常痛苦的多线程程序编码，


三、进程之间是怎么进行通信的？
1.Queue使用方法：
Queue.qsize()：返回当前队列包含的消息数量；
Queue.empty()：如果队列为空，返回True，反之False ；
Queue.full()：如果队列满了，返回True,反之False；
Queue.get():获取队列中的一条消息，然后将其从列队中移除，可传参超时时长。
Queue.get_nowait()：相当Queue.get(False),取不到值时触发异常：Empty；
Queue.put():将一个值添加进数列，可传参超时时长。
Queue.put_nowait():相当于Queue.get(False),当队列满了时报错：Full。

#!/usr/bin/env python3

import time
from multiprocessing import Process,Queue

q = Queue()  #创建列队，不传数字表示列队不限数量
for i in range(11):
    q.put(i)

def A():
    while 1:
        try:
            num = q.get_nowait()
            print('我是进程A,取出数字:%d'%num)
            time.sleep(1)
        except :
            break

def B():
    while 1:
        try:
            num = q.get_nowait()
            print('我是进程B,取出数字:%d'%num)
            time.sleep(1)
        except :
            break

p1 = Process(target = A)
p2 = Process(target = B)
p1.start()
p2.start()

我是进程A,取出数字:0
我是进程B,取出数字:1
我是进程A,取出数字:2
我是进程B,取出数字:3
我是进程A,取出数字:4
我是进程B,取出数字:5
我是进程B,取出数字:6
我是进程A,取出数字:7
我是进程B,取出数字:8
我是进程A,取出数字:9
我是进程B,取出数字:10


使用进程池Pool时，Queue会出错，需要使用Manager.Queue：
#!/usr/bin/env python3

import time
from multiprocessing import Pool,Manager,Queue

q = Manager().Queue()
for i in range(11):
    q.put(i)

def A(i):
    num = q.get_nowait()
    print('我是进程%d,取出数字:%d'%(i,num))
    time.sleep(1)
            

pool = Pool(3)

for i in range(10):
    pool.apply_async(A,(i,))

pool.close()
pool.join()
我是进程1,取出数字:0
我是进程0,取出数字:1
我是进程2,取出数字:2
我是进程4,取出数字:3
我是进程3,取出数字:4
我是进程5,取出数字:5
我是进程6,取出数字:6
我是进程7,取出数字:7
我是进程8,取出数字:8
我是进程9,取出数字:9

四、@staticmethod和@classmethod的区别？
一般来说，要使用某个类的方法，需要先实例化一个对象再调用方法。

而使用@staticmethod或@classmethod，就可以不需要实例化，直接类名.方法名()来调用。

这有利于组织代码，把某些应该属于某个类的函数给放到那个类里去，同时有利于命名空间的整洁
@staticmethod不需要表示自身对象的self和自身类的cls参数，就跟使用函数一样。
@classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。
如果在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名。
而@classmethod因为持有cls参数，可以来调用类的属性，类的方法，实例化对象等
class A(object):  
    bar = 1  
    def foo(self):  
        print 'foo'  
 
    @staticmethod  
    def static_foo():  
        print 'static_foo'  
        print A.bar  
 
    @classmethod  
    def class_foo(cls):  
        print 'class_foo'  
        print cls.bar  
        cls().foo()  
  
A.static_foo()  
A.class_foo()  
输出
static_foo
1
class_foo
1
foo

五、python里面如何拷贝一个对象，并解释深浅拷贝？
浅拷贝只是拷贝了一系列引用，
当我们在拷贝出来的对象对可修改的数据类型进行修改的时候，并没有改变引用，所以会影响原对象。
而对不可修改的对象进行修改的是，则是新建了对象，刷新了引用，所以和原对象的引用不同，结果也就不同

那么深拷贝不就是将里面引用的对象重新创建了一遍并生成了一个新的一系列引用。
基本上是这样的，但是对于字符串、数字等不可修改的对象来说，重新创建一份似乎有点浪费内存，
反正你到时要修改的时候都是新建对象，刷新引用的。所以还用原来的引用也无所谓，还能达到节省内存的目的。


六、python中search()和match()的区别？
match位于字符串的开头、
search搜索整个字符串

七、迭代器和生成器的区别？
迭代器的实质是实现了next()方法的对象，常用的元组、列表、字典都是迭代器
迭代器中重点关注两个方法：
__iter__方法：返回迭代器自身。可以通过python内建函数iter()调用
__next__方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回
就会引发一个StopIteration异常。该方法可以通过python内建函数next()调用

生成器：
简单来说，生成器是包含yield关键词的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议
同时yield内部是一个状态机，维护着挂起和继续的状态、
a. 当生成器被调用的时候，函数体的代码不会被执行，而是会返回一个迭代器，其实，生成器函数返回生成器的迭代器。 
“生成器的迭代器”这个术语通常被称作”生成器”。要注意的是生成器就是一类特殊的迭代器。作为一个迭代器，生成器必须要定义一些方法，
其中一个就是next()。如同迭代器一样，我们可以使用next()函数来获取下一个值。需要明白的是，这一切都是在yield内部实现的。

b. 当next()方法第一次被调用的时候，生成器函数才开始执行，执行到yield语句处停止,next()方法的返回值就是yield语句处的参数（yielded value）
当继续调用next()方法的时候，函数将接着上一次停止的yield语句处继续执行，并到下一个yield处停止；如果后面没有yield就抛出StopIteration异常。

c.每调用一次生成器的next()方法，就会执行生成器中的代码，知道遇到一个yield或者return语句。yield语句意味着应该生成一个值（在上面已经解释清楚）。
return意味着生成器要停止执行，不在产生任何东西。

d. 生成器的编写方法和函数定义类似，只是在return的地方改为yield。生成器中可以有多个yield。当生成器遇到一个yield时，会暂停运行生成器，返回yield后面的值。
当再次调用生成器的时候，会从刚才暂停的地方继续运行，直到下一个yield。生成器自身又构成一个循环器，每次循环使用一个yield返回的值

八、什么事协程，python协程是怎么实现的？
   协程就是在一个线程执行过程中可以在一个子程序的预定或者随机位置中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。它本身就是一种特殊的子程序或者成为函数
  协程基于generator，python3中内置了异步I/O。
  Python里面一般用gevent实现协程， 而协程就是在等待的时候切换去做别的操作，相当于将一个线程分块，充分利用资源

九、什么是装饰器？
 装饰器本质上是一个python函数，它可以让其它函数在不需要做任何代码变动的前提下增加额外的功能，装饰器的返回值也是一个函数对象
 有了装饰器我们就可以抽离大量与函数功能本身无关的雷同代码并继续重用

十、简述一下select和epoll的原理和区别？
 select,poll,epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是 读就绪或写就绪），能够通知程序进行相应的读写操作
。但select,poll,epoll本质上都是同步I/O，因为他们都是
需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间
内核中的select实现中,它是采用轮询来处理的,轮询的fd数据数据越多,自然耗时就越多.,epoll最大的好处在于它不会随着监听fd数目的增长而降低效率
在selec中采用轮询处理，其中的数据结构类似一个数组的数据结构，而epoll
是维护一个队列，直接看队列是不是空就可以了。epoll只会对"活跃"的socket进行操作---这是因为在内核实现中epoll是根据每个fd上面
的callback函数实现的。那么，只有"活跃"的socket才会主动的去调用 
callback函数（把这个句柄加入队列），其他idle状态句柄则不会，在这点上，epoll实现了一个"伪"AIO。但是如果绝大部分的I/O都是
“活跃的”，每个I/O端口使用率很高的话，epoll效率不一定比select高（可能是要维护队列复杂）。

十一、python的垃圾回收机制？
Python的GC模块主要运用了“引用计数”（reference counting）来跟踪和回收垃圾。在引用计数的基础上，还可以通过“标记-清除”（mark and sweep）
解决容器对象可能产生的循环引用的问题。通过“分代回收”（generation collection）以空间换取时间来进一步提高垃圾回收的效率。
引用计数：
在python中，大多数对象的生命周期都是通过对象的引用技术来管理。
原理：当一个对象的引用被创建
或者复制时，对象的引用计数加1，当一个对象的引用被销毁时，对象的引用计数减1；当对象的引用计数为0时，就意味着对象已经没有了任何人使用了，可以将其所占用的内存释放了
标记清除是为了解决 循环引用的问题。可以包含其它对象的容器对象（比如：list，set,dict,class,instance）都可以产生循环引用
原理：“标记-清除”采用了更好的做法，我们并不改动真实的引用计数，而是将集合中对象的引用计数复制一份副本，改动该对象引用的副本。对于副本做任何的改动，都不会影响到对象生命走起的维护。

这个计数副本的唯一作用是寻找root object集合（该集合中的对象是不能被回收的）。当成功寻找到root object集合之后，首先将现在的内存链表一分为二，一条链表中维护root object集合，
成为root链表，而另外一条链表中维护剩下的对象，成为unreachable链表。之所以要剖成两个链表，是基于这样的一种考虑：现在的unreachable可能存在被root链表中的对象，直接或间接引用的对象，
这些对象是不能被回收的，一旦在标记的过程中，发现这样的对象，就将其从unreachable链表中移到root链表中；当完成标记后，unreachable链表中剩下的所有对象就是名副其实的垃圾对象了，
接下来的垃圾回收只需限制在unreachable链表中即可。


原理：将系统中的所有内存块根据其存活时间划分为不同的集合，每一个集合就成为一个“代”，垃圾收集的频率随着“代”的存活时间的增大而减小。
也就是说，活得越长的对象，就越不可能是垃圾，就应该减少对它的垃圾收集频率。那么如何来衡量这个存活时间：通常是利用几次垃圾收集动作来衡量，
如果一个对象经过的垃圾收集次数越多，可以得出：该对象存活时间就越长。

十二、python socket编程？
两个程序通过“网络”交互数据就使用socket，它只负责两件事：建立连接，传递数据
socket通常也称为作“套接字”，用于描述IP地址和端口，是一个通信链的句柄，应用程序通常通过“套接字”向网络发出请求或者应答网络请求
socket和file的区别：
file模块是针对某个指定文件进行打开、读写、关闭
socket模块是针对服务器端和客户端socket进行打开、读写、关闭
SocketTCP服务器编程步骤：1、打开socket，2、绑定到一个地址和端口，3、侦听进来的连接，4、接受连接，5、读写数据，6、关闭socket。      
SocketTCP客户端编程步骤：1、打开socket，2、连接到服务器，3、读写数据，4、关闭socket。

十三、TCP和HTTP的区别？
TCP协议对应于传输层，而HTTP协议对应于应用层，从本质上来说，二者没有 可比性。Http协议是建立在TCP协议基础之上的，
当浏览器需要从服务器获取网页数据的时候，会发出一次Http请求。Http会通过TCP建立起一个 到服务器的连接通道，
当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连 
接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立 一个新的连接。如果是一个连接的话，
服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，
所以记不住任何状态，成为无状态连接。
Http是无状态的短连接，而TCP是有状态的长连接

十四、MylSAM和InnoDB的特点？
是mysql的两个引擎
myisam支持全文检索(fulltext),操作表的时候是表级锁，不支持事务，日志，外键等。
innodb则支持事务处理，日志，外键。但不支持全文检索。操作表的时候是行级锁。
由于有事务和日志，所以innodb在添加和修改的时候数据更安全，但是读取速度较慢。





